---
title: "Quickstart"
description: "Welcome to OnCall CLI! This quickstart gets you using AI‑powered debugging in minutes—install, initialize, log in, run your first AI‑assisted session, and iterate with the built‑in tools."
icon: "bolt"
---

### Prerequisites

Before starting, ensure you have:
- **Node.js 18+** installed on your machine.
- A project directory to run commands in.

### Step 1: Get your API Key

You cannot use the CLI without a valid API key.

1.  Go to the **[OnCall Dashboard](https://app.oncall.build)**.
2.  Sign in or create a new account.
3.  Navigate to **Settings > API Keys**.
4.  Click **"Generate New Key"** and copy the string (it starts with `oc_`).

> **Note:** Keep this key safe. You will need it for the login step below.

### Step 2: Install OnCall‑CLI

Run the following command in your terminal:

```bash
npm install -g oncall-cli
```

### Step 3: Initialize your project

Navigate to your project folder and initialize OnCall:

```bash
cd /path/to/your/project
oncall init -m "Describe this service" -id "<project-id>"
```

- This command creates an `oncall.yaml` file with your `id`, `window_id`, and access flags (`logs_available` / `code_available`).
- **Tip:** Use the same `id` across different services (e.g., frontend, backend) to group them into one cluster.

### Step 4: Log in

Authenticate your machine using the key you generated in Step 1:

```bash
oncall login <your-api-key>
```

- This stores your `API_KEY` securely in `~/.oncall/config`.

### Step 5: Start the cluster server

If you are debugging multiple services, run this in a separate terminal window:

```bash
oncall cluster
```

- This keeps a local registry so the AI can see all services sharing the same project `id` and reason across them.

### Step 6: Run your first AI‑assisted session

Prefix your usual startup command with `oncall`:

```bash
oncall npm run dev
# or
oncall python app.py
# or
oncall docker-compose up
```

**What happens:**
- The command runs in a pseudo‑terminal; logs stream live.
- The CLI opens a WebSocket to the backend with your `API_KEY` + `window_id`.
- You get a split UI: **Logs** on the left, **AI Chat** on the right.

### Step 7: Ask your first question

Type in the chat pane on the right:

- “What’s causing this error?”
- “Why are API requests failing?”
- “What just happened?”

The CLI sends your question plus recent logs (and cluster architecture if available). The AI may call local tools:
- **Logs:** `tail_logs`, `grep_logs`, `get_recent_errors`, `read_logs` (requires `logs_available: true`)
- **Code:** `read_file`, `grep_search` (requires `code_available: true`)

### Step 8: Iterate quickly

Use these shortcuts to navigate the interface:

- `Ctrl+R`: Reset chat context.
- `Ctrl+D`: Cycle views (Split View → Full Chat → Full Logs).
- `Tab`: Switch focus between panes; `↑/↓` to scroll the focused pane.
- `Ctrl+L`: Clear logs; `Ctrl+K`: Clear chat.

### Minimal “hello” run

Want to test it without a full project? Try this:

```bash
oncall init -m "Quick test"
oncall login <your-api-key>
oncall node -e "console.log('hello from oncall')"
```

Then ask in the chat pane: “What did this command output?”